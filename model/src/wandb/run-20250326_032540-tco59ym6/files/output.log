  0%|                                                                                           | 0/110 [00:00<?, ?it/s]C:\Users\USER\Desktop\Personal\code\mbti-translator\model\mbti_env\Lib\site-packages\torch\_dynamo\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
 11%|████████▉                                                                         | 12/110 [01:45<12:20,  7.55s/it]C:\Users\USER\Desktop\Personal\code\mbti-translator\model\mbti_env\Lib\site-packages\torch\_dynamo\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
{'loss': 3.7276, 'grad_norm': 2.6226484775543213, 'learning_rate': 0.00016363636363636366, 'epoch': 0.87}
  return fn(*args, **kwargs)                                                                                            
{'eval_loss': 2.72040057182312, 'eval_runtime': 4.2692, 'eval_samples_per_second': 4.919, 'eval_steps_per_second': 2.577, 'epoch': 1.0}
 22%|█████████████████▉                                                                | 24/110 [03:28<10:04,  7.03s/it]C:\Users\USER\Desktop\Personal\code\mbti-translator\model\mbti_env\Lib\site-packages\torch\_dynamo\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
{'loss': 2.4912, 'grad_norm': 2.0743629932403564, 'learning_rate': 0.00019679487013963564, 'epoch': 1.7}
  return fn(*args, **kwargs)                                                                                            
{'eval_loss': 2.2491068840026855, 'eval_runtime': 4.0204, 'eval_samples_per_second': 5.223, 'eval_steps_per_second': 2.736, 'epoch': 2.0}
 33%|██████████████████████████▊                                                       | 36/110 [05:11<08:46,  7.11s/it]C:\Users\USER\Desktop\Personal\code\mbti-translator\model\mbti_env\Lib\site-packages\torch\_dynamo\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
{'loss': 2.1452, 'grad_norm': 1.532122015953064, 'learning_rate': 0.00018412535328311814, 'epoch': 2.52}
  return fn(*args, **kwargs)                                                                                            
{'eval_loss': 2.2109532356262207, 'eval_runtime': 4.0637, 'eval_samples_per_second': 5.168, 'eval_steps_per_second': 2.707, 'epoch': 3.0}
 44%|███████████████████████████████████▊                                              | 48/110 [06:54<07:24,  7.17s/it]C:\Users\USER\Desktop\Personal\code\mbti-translator\model\mbti_env\Lib\site-packages\torch\_dynamo\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
{'loss': 2.0135, 'grad_norm': 1.7076311111450195, 'learning_rate': 0.00016305526670845226, 'epoch': 3.35}
  return fn(*args, **kwargs)                                                                                            
{'eval_loss': 2.216630458831787, 'eval_runtime': 4.0052, 'eval_samples_per_second': 5.243, 'eval_steps_per_second': 2.746, 'epoch': 4.0}
 55%|████████████████████████████████████████████▋                                     | 60/110 [08:36<06:00,  7.20s/it]C:\Users\USER\Desktop\Personal\code\mbti-translator\model\mbti_env\Lib\site-packages\torch\_dynamo\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
{'loss': 1.8366, 'grad_norm': 2.102311372756958, 'learning_rate': 0.00013568862215918717, 'epoch': 4.17}
{'loss': 1.6597, 'grad_norm': 3.8947594165802, 'learning_rate': 0.00010475819158237425, 'epoch': 5.0}
  return fn(*args, **kwargs)                                                                                            
{'eval_loss': 2.2754530906677246, 'eval_runtime': 4.0245, 'eval_samples_per_second': 5.218, 'eval_steps_per_second': 2.733, 'epoch': 5.0}
 65%|█████████████████████████████████████████████████████▋                            | 72/110 [10:19<04:37,  7.30s/it]C:\Users\USER\Desktop\Personal\code\mbti-translator\model\mbti_env\Lib\site-packages\torch\_dynamo\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
{'loss': 1.5432, 'grad_norm': 2.73460054397583, 'learning_rate': 7.335261863099651e-05, 'epoch': 5.87}
  return fn(*args, **kwargs)                                                                                            
{'eval_loss': 2.338569164276123, 'eval_runtime': 4.2334, 'eval_samples_per_second': 4.961, 'eval_steps_per_second': 2.598, 'epoch': 6.0}
 76%|██████████████████████████████████████████████████████████████▌                   | 84/110 [12:04<03:13,  7.44s/it]C:\Users\USER\Desktop\Personal\code\mbti-translator\model\mbti_env\Lib\site-packages\torch\_dynamo\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
{'loss': 1.4497, 'grad_norm': 2.6854472160339355, 'learning_rate': 4.4607993613388976e-05, 'epoch': 6.7}
  return fn(*args, **kwargs)                                                                                            
{'eval_loss': 2.3724653720855713, 'eval_runtime': 4.313, 'eval_samples_per_second': 4.869, 'eval_steps_per_second': 2.55, 'epoch': 7.0}
 87%|███████████████████████████████████████████████████████████████████████▌          | 96/110 [13:46<01:39,  7.13s/it]C:\Users\USER\Desktop\Personal\code\mbti-translator\model\mbti_env\Lib\site-packages\torch\_dynamo\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
{'loss': 1.3569, 'grad_norm': 2.4225738048553467, 'learning_rate': 2.139469052572127e-05, 'epoch': 7.52}
  return fn(*args, **kwargs)                                                                                            
{'eval_loss': 2.3958866596221924, 'eval_runtime': 4.013, 'eval_samples_per_second': 5.233, 'eval_steps_per_second': 2.741, 'epoch': 8.0}
 98%|███████████████████████████████████████████████████████████████████████████████▌ | 108/110 [15:26<00:14,  7.07s/it]C:\Users\USER\Desktop\Personal\code\mbti-translator\model\mbti_env\Lib\site-packages\torch\_dynamo\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
{'loss': 1.3587, 'grad_norm': 2.816594123840332, 'learning_rate': 6.030737921409169e-06, 'epoch': 8.35}
  return fn(*args, **kwargs)                                                                                            
{'eval_loss': 2.4058303833007812, 'eval_runtime': 4.3488, 'eval_samples_per_second': 4.829, 'eval_steps_per_second': 2.529, 'epoch': 9.0}
100%|█████████████████████████████████████████████████████████████████████████████████| 110/110 [15:49<00:00,  8.63s/it]
{'loss': 1.3181, 'grad_norm': 2.5622951984405518, 'learning_rate': 5.0345761681491746e-08, 'epoch': 9.17}
100%|███████████████████████████████████████████████████████████████████████████████████| 11/11 [00:03<00:00,  3.10it/s]
{'eval_loss': 2.4058420658111572, 'eval_runtime': 3.9531, 'eval_samples_per_second': 5.312, 'eval_steps_per_second': 2.783, 'epoch': 9.17}
{'train_runtime': 951.2556, 'train_samples_per_second': 1.924, 'train_steps_per_second': 0.116, 'train_loss': 1.9000372193076394, 'epoch': 9.17}
Final evaluation results: {'eval_loss': 2.2109532356262207, 'eval_runtime': 3.9073, 'eval_samples_per_second': 5.375, 'eval_steps_per_second': 2.815, 'epoch': 9.173913043478262, 'perplexity': 9.124409675598145}
Completed training for ISTP
